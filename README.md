<div align="center">
  <img src="./client/public/favicon.png" alt="SonicBridge Logo" width="350"/>
  <br/>
  <h1>SonicBridge ğŸ™ï¸âš¡ğŸŒ</h1>
  <p><strong>Real-time AI speech translation for classrooms, meetings, and live events.</strong></p>
  <br/>

  [![Live Demo](https://img.shields.io/badge/ğŸ”´_LIVE_DEMO-sonic--bridge--cyan.vercel.app-00C853?style=for-the-badge)](https://sonic-bridge-cyan.vercel.app)
  [![GitHub](https://img.shields.io/badge/GitHub-SonicBridge-181717?style=for-the-badge&logo=github)](https://github.com/SaiDheeraj-19/SonicBridge)

</div>

---

**SonicBridge** is a production-ready, real-time speech-to-speech translation platform built for **classrooms, meetings, and conferences**. A speaker talks naturally in their language â€” listeners hear the translated speech in their chosen language, live. Built with Sarvam AI's Indic language models for unmatched accuracy across 10+ Indian languages.

## ğŸ¯ Use Cases

| Scenario | How SonicBridge Helps |
|----------|----------------------|
| ğŸ« **Classrooms** | Professor lectures in English â†’ Students hear in Telugu, Hindi, Tamil, etc. with scrollable transcript |
| ğŸ¢ **Corporate Meetings** | Multi-lingual teams collaborate without language barriers |
| ğŸ¤ **Conferences & Events** | Speaker broadcasts to hundreds of participants in their preferred language |
| ğŸ¥ **Healthcare** | Doctors communicate with patients across language barriers |

## âœ¨ Key Features

### Core Platform
- **Real-Time Speech Translation** â€” Speak in one language, listeners hear in another within ~4-6 seconds
- **10+ Indian Languages** â€” Hindi, Telugu, Tamil, Kannada, Malayalam, Marathi, Bengali, Gujarati, Odia, Punjabi
- **Text + Voice Output** â€” Participants see translated text AND hear TTS audio simultaneously
- **Room-Based Sessions** â€” Secure 8-character room codes, shareable via one-click copy

### Classroom-Grade Intelligence
- **Sentence Accumulation** â€” Waits for complete sentences (`.` `?` `!`) before translating, producing coherent output instead of fragments
- **Smart Silence Detection** â€” Tracks consecutive voiced/silent chunks. Teacher pausing to write on the board generates zero hallucinations
- **Anti-Hallucination System** â€” 3-layer filter: exact match (40+ words), short fragment detection, repetitive text detection
- **Scrolling Transcript** â€” Students see a scrollable list of individually translated sentences with timestamps for reference

### Audio Engineering
- **Bulletproof Audio Queue** â€” Safety timeouts, double-advance guards, and a 3-second watchdog prevent audio from ever getting stuck
- **Browser Autoplay Unlock** â€” Tap-to-enable overlay satisfies browser policies, then auto-plays all queued audio
- **2x Gain Boost** â€” TTS output amplified through Web Audio GainNode for clear classroom playback
- **AudioWorklet Processing** â€” 128ms buffer (2048 samples @ 16kHz) for low-latency capture without blocking the UI thread

### Voice Isolation Pipeline
- **Layer 1**: Browser-level noise suppression, echo cancellation, auto-gain (WebRTC constraints)
- **Layer 2**: RNNoise neural suppression (production-ready, disabled in dev)
- **Layer 3**: Energy-based VAD with zero-crossing rate analysis (threshold: 200 + ZCR filter)
- **Layer 4**: SpeechBrain speaker verification via cosine similarity (auto-detected microservice)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     WebSocket (Binary PCM)     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HOST (Browser)    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚   Node.js Server     â”‚
â”‚                     â”‚                                 â”‚                      â”‚
â”‚ â€¢ getUserMedia      â”‚                                 â”‚ â€¢ VAD + Silence Trackâ”‚
â”‚ â€¢ AudioWorklet      â”‚                                 â”‚ â€¢ WAV Header Inject  â”‚
â”‚ â€¢ PCM 16kHz 16-bit  â”‚                                 â”‚ â€¢ Buffer â†’ Sarvam STTâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚ â€¢ Translate â†’ TTS    â”‚
                                                        â”‚ â€¢ Sentence Accumulateâ”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     WebSocket (JSON + WAV)      â”‚                      â”‚
â”‚ PARTICIPANT (Browser)â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â€¢ Broadcast per-lang â”‚
â”‚                     â”‚                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â€¢ Translated Text   â”‚                                          â”‚
â”‚ â€¢ TTS Audio Playbackâ”‚                                          â–¼
â”‚ â€¢ Scrolling List    â”‚                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ GainNode 2x Boost â”‚                                 â”‚   Sarvam AI APIs     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚ â€¢ STT (saaras:v2.5)  â”‚
                                                        â”‚ â€¢ Translation        â”‚
                                                        â”‚ â€¢ TTS (streaming)    â”‚
                                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

<div align="center">
  <table>
    <tr>
      <td align="center"><strong>Frontend</strong><br/><code>React 19 + Vite</code><br/><code>Tailwind CSS</code><br/><code>Web Audio API</code></td>
      <td align="center"><strong>Backend</strong><br/><code>Node.js + Express</code><br/><code>ws WebSockets</code><br/><code>Binary Audio Streams</code></td>
      <td align="center"><strong>AI Pipeline</strong><br/><code>Sarvam AI STT</code><br/><code>Sarvam Translation</code><br/><code>Sarvam TTS</code></td>
      <td align="center"><strong>Infrastructure</strong><br/><code>Vercel (Frontend)</code><br/><code>Render (Backend)</code><br/><code>Docker (Optional)</code></td>
    </tr>
  </table>
</div>

## ğŸš€ Getting Started

### Prerequisites
- Node.js (v18+)
- Sarvam AI API Key â†’ [sarvam.ai](https://www.sarvam.ai/)

### Environment Setup

Create `.env` in the `server/` directory:
```env
SARVAM_API_KEY=your_sarvam_api_key_here
PORT=5000
```

Create `.env` in the `client/` directory:
```env
VITE_WS_URL=ws://localhost:5000
```

### Installation

```bash
# 1. Clone
git clone https://github.com/SaiDheeraj-19/SonicBridge.git
cd SonicBridge

# 2. Start Backend
cd server
npm install
npm run dev

# 3. Start Frontend (new terminal)
cd ../client
npm install
npm run dev
```

Visit `http://localhost:5173` to launch your first session.

### Docker (Optional)

```bash
docker-compose up --build
```

## ğŸ§ How It Works

### For the Host (Speaker)
1. **Create Room** â€” Click "Create Room" to generate a unique 8-character code
2. **Share Code** â€” Copy the room code or share the URL with participants
3. **Start Speaking** â€” Click the mic button and speak naturally
4. **Live Transcript** â€” See your speech transcribed in real-time on screen

### For Participants (Listeners)
1. **Join Room** â€” Enter the room code and select your target language
2. **Tap to Enable Audio** â€” One tap unlocks browser audio playback
3. **Listen & Read** â€” Hear translated speech audio + see scrolling text transcript
4. **Scroll Back** â€” Review previous sentences anytime during the session

## âš¡ Latency Breakdown

| Pipeline Stage | Latency |
|----------------|---------|
| Audio capture (AudioWorklet) | ~128ms |
| WebSocket transport | ~10ms (local) / ~300ms (deployed) |
| VAD + silence detection | <1ms |
| STT buffer accumulation | ~2000ms |
| Sarvam STT API | ~500-1500ms |
| Sarvam Translation API | ~300-600ms |
| Sarvam TTS API | ~1000-2000ms |
| Audio decode + playback | ~50ms |
| **Total end-to-end** | **~4-6 seconds** |

## ğŸ“ Project Structure

```
SonicBridge/
â”œâ”€â”€ client/                      # React Frontend
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ audio-processor.js   # AudioWorklet (PCM capture)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx              # Main app (Host + Participant views)
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useAudioRecorder.js  # Mic capture hook
â”‚   â”‚   â”‚   â””â”€â”€ useWebSocket.js      # WS connection hook
â”‚   â”‚   â””â”€â”€ index.css            # Design system
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ server/                      # Node.js Backend
â”‚   â”œâ”€â”€ server.js                # WebSocket server + room management
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ sarvamService.js     # Sarvam AI API integration
â”‚   â”‚   â””â”€â”€ voiceIsolationService.js  # VAD + voice isolation
â”‚   â””â”€â”€ speechbrain_service/     # Optional Python microservice
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ›¡ï¸ Privacy & Security

- **No Audio Storage** â€” Audio data is processed in real-time and discarded after the session
- **Room Isolation** â€” Each session operates in an isolated room with a unique cryptographic code
- **Host-Only Audio** â€” Only the host can broadcast; participants are listen-only
- **Transient Sessions** â€” All data (transcripts, audio, state) is destroyed when the room closes

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

<br/>

<div align="center">
  <p>Â© 2026 SonicBridge Â· Built with â¤ï¸ for breaking language barriers</p>
  <p><sub>v3.0.0 Â· Classroom-Ready Edition</sub></p>
</div>
